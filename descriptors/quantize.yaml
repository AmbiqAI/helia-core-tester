operator: Quantize
name: quantize_f32_int8
activation_dtype: S8
weight_dtype: S8
activation: NONE
hint:
  call_style: per_tensor
input_shape: [1, 1, 8, 1]
filter_shape: [1, 1, 1, 1]
---
operator: Quantize
name: quantize_f32_int16
activation_dtype: S16
weight_dtype: S8
activation: NONE
hint:
  call_style: per_tensor
input_shape: [1, 1, 8, 1]
filter_shape: [1, 1, 1, 1]
---
operator: Quantize
name: quantize_int8_int8
activation_dtype: S8
weight_dtype: S8
activation: NONE
hint:
  call_style: per_tensor
input_shape: [1, 1, 8, 1]
filter_shape: [1, 1, 1, 1]
---
operator: Quantize
name: quantize_int16_int16
activation_dtype: S8
weight_dtype: S8
activation: NONE
hint:
  call_style: per_tensor
input_shape: [1, 1, 8, 1]
filter_shape: [1, 1, 1, 1]

